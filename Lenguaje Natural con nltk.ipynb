{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.data import load\n",
    "from nltk.stem import SnowballStemmer\n",
    "from string import punctuation\n",
    "from nltk import wordpunct_tokenize\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "from geotext import GeoText\n",
    "from gensim.models import KeyedVectors\n",
    "vectors = KeyedVectors.load_word2vec_format('C:/Users/pneira/Desktop/fasttext/fasttext-sbwc.3.6.e20.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopword\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "spanish_stopwords.extend(['de','del','i','ii','iii','iv','v','vi','viii','ix','x'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quitamos numeros y signos de puntuación\n",
    "non_words = list(punctuation)\n",
    "#Y agregamos, los signos españoles\n",
    "non_words.extend(['¿', '¡'])\n",
    "non_words.extend(map(str,range(10)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos funciones, y el stemmer\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "def quitar_geo(text):\n",
    "        places = GeoText(text.title())\n",
    "        for i in range(0,np.shape(places.cities)[0]):\n",
    "            text=text.title().replace(places.cities[i],'')\n",
    "        return text\n",
    "def unique_list(l):\n",
    "        ulist = []\n",
    "        [ulist.append(x) for x in l if x not in ulist]\n",
    "        return ulist    \n",
    "def stem_tokens(tokens, stemmer):\n",
    "        stemmed = []\n",
    "        for item in tokens:\n",
    "            stemmed.append(stemmer.stem(item))\n",
    "        return stemmed\n",
    "def most_similar(text):\n",
    "        ulist = []\n",
    "        [ulist.append(x) for x in text.split() if x not in ulist]\n",
    "        text=' '.join(unique_list(text.split()))\n",
    "    return ulist    \n",
    "        \n",
    "def tokenize(text):\n",
    "        #Quitar ciudades\n",
    "        text=quitar_geo(text)\n",
    "        #lowercase\n",
    "        text = text.lower()\n",
    "        # remove links from tweets\n",
    "        text = re.sub(r\"http\\S+\", \"https\", text)\n",
    "        #Quitar más similares\n",
    "        #############################\n",
    "        # quitar puntuación\n",
    "        trans_tab = dict.fromkeys(map(ord, u'\\u0301\\u0308'), None)\n",
    "        text = normalize('NFKC', normalize('NFKD', text).translate(trans_tab))\n",
    "        text = ''.join([c for c in text if c not in non_words])\n",
    "        # quitar repetidos\n",
    "        text = re.sub(r'(.)\\1+', r'\\1\\1', text) #que cresta hace esto???\n",
    "        text=' '.join(unique_list(text.split()))\n",
    "        # tokenize\n",
    "        tokens =  word_tokenize(text)\n",
    "        #quitamos stoping words\n",
    "        tokens= [item for item in tokens if item not in spanish_stopwords]\n",
    "        # stem\n",
    "        try:\n",
    "            stems = stem_tokens(tokens, stemmer)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            stems = ['']\n",
    "        return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "text='PROYECTO DE REPARACIÓN reparar INTEGRAL DE 4 VIVIENDAS DEL CONJUNTO HABITACIONAL PUNTA ARENAS II ETAPA. dél acá, viviendas viviéndas moños'\n",
    "tokens=tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['proyect',\n",
       " 'reparacion',\n",
       " 'repar',\n",
       " 'integral',\n",
       " 'viviend',\n",
       " 'conjunt',\n",
       " 'habitacional',\n",
       " 'etap',\n",
       " 'aca',\n",
       " 'moñ']"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PROYECTO DE REPARACIÓN INTEGRAL DE 4 VIVIENDAS DEL CONJUNTO HABITACIONAL PUNTA ARENAS II ETAPA. dél acá, viviendas viviéndas moños'"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Punta Arenas'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places = GeoText( 'hasta Punta Arenas, ciudad de Valparaiso')\n",
    "places.cities[0]\n",
    "#places.countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Proyecto De Reparación Integral De 4 Viviendas Del Conjunto Habitacional  Ii Etapa. Dél Acá, Viviendas Viviéndas Moños'"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.title().replace(places.cities[i],'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reparación', 'reparaciones', 'reparacion']"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text='reparación reparaciones reparacion'\n",
    "ulist = []\n",
    "[ulist.append(x) for x in text.split() if x not in ulist]\n",
    "ulist\n",
    "#text=' '.join(unique_list(text.split()))\n",
    "#text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reparaciones', 0.7847789525985718),\n",
       " ('reparar', 0.7376405000686646),\n",
       " ('repararse', 0.6819849014282227),\n",
       " ('autoreparación', 0.6721078157424927),\n",
       " ('reparacion', 0.6715101003646851),\n",
       " ('reparacián', 0.6694834232330322),\n",
       " ('reparaciónes', 0.669452428817749),\n",
       " ('reparativa', 0.6618856191635132),\n",
       " ('reparan', 0.6592204570770264),\n",
       " ('reparable', 0.6591182351112366)]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.most_similar([ulist[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
